# -*- coding: utf-8 -*-
"""Task 6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rheGwWo9Z0GQWbEDzZrDShRA9Vgx3Y66
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.decomposition import PCA
from matplotlib.colors import ListedColormap

# 1. Load dataset from CSV
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data"
columns = ['ID', 'Diagnosis'] + [f'feature_{i}' for i in range(1, 31)]
df = pd.read_csv(url, header=None, names=columns)

#Map Diagnosis: M -> 1, B -> 0

df['Diagnosis'] = df['Diagnosis'].map({'M':1, 'B':0})

# Features and target

X = df.iloc[:, 2:].values
y = df['Diagnosis'].values

# 2. Train-Test Split


X_train, X_test, y_train, y_test = train_test_split(
X, y, test_size=0.3, random_state=42, stratify=y
)

# 3. Feature Scaling

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 4. Hyperparameter Tuning (K)

param_grid = {'n_neighbors': np.arange(1, 21)}
knn = KNeighborsClassifier()
grid = GridSearchCV(knn, param_grid, cv=5)
grid.fit(X_train_scaled, y_train)

best_knn = grid.best_estimator_
print(f"Best K: {best_knn.n_neighbors}")


# 5. Predictions and Evaluation

y_pred = best_knn.predict(X_test_scaled)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))


# 6. K vs Accuracy Plot

accuracies = []
k_values = np.arange(1, 21)

for k in k_values:
    knn_temp = KNeighborsClassifier(n_neighbors=k)
    knn_temp.fit(X_train_scaled, y_train)
    y_pred_temp = knn_temp.predict(X_test_scaled)
    accuracies.append(accuracy_score(y_test, y_pred_temp))

plt.figure(figsize=(8,5))
plt.plot(k_values, accuracies, marker='o')
plt.xlabel('Number of Neighbors (K)')
plt.ylabel('Accuracy')
plt.title('K vs Accuracy for KNN')
plt.xticks(k_values)
plt.grid(True)
plt.show()

# 7. PCA Visualization (2D)

pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_train_scaled)
X_test_pca = pca.transform(X_test_scaled)

knn_pca = KNeighborsClassifier(n_neighbors=best_knn.n_neighbors)
knn_pca.fit(X_pca, y_train)

# Decision boundary

h = 0.02
x_min, x_max = X_pca[:, 0].min() - 1, X_pca[:, 0].max() + 1
y_min, y_max = X_pca[:, 1].min() - 1, X_pca[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
Z = knn_pca.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)

plt.figure(figsize=(8,6))
cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA'])
cmap_bold = ListedColormap(['#FF0000', '#00FF00'])
plt.contourf(xx, yy, Z, alpha=0.3, cmap=cmap_light)
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_train, cmap=cmap_bold, edgecolor='k', s=50)
plt.scatter(X_test_pca[:, 0], X_test_pca[:, 1], c=y_test, cmap=cmap_bold, edgecolor='yellow', s=80, marker='*')
plt.xlabel('PCA Component 1')
plt.ylabel('PCA Component 2')
plt.title(f'KNN Decision Boundary with PCA (k={best_knn.n_neighbors})')
plt.show()

